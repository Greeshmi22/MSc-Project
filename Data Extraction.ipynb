{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4639998-d496-4ca8-9b7d-f8c0f458ece8",
   "metadata": {},
   "source": [
    "<h2 style=\"color:Black;\">Module Code: CSMPR - MSc Project</h2>\n",
    "\n",
    "<h2 style=\"color:Black;\">Project Title: Predictive Modelling of Extreme Rainfalls</h2>\n",
    "\n",
    "<h3 style=\"color:Black;\">Student Number: <span style=\"color:green;\">32822955</span></h3>\n",
    "\n",
    "<h3 style=\"color:Black;\">Acknowledgments: Supervisor - Professor. Atta Badii, Researcher - Kieran Hunt </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0aa0ba-a0bf-4115-8250-0fb794d859b2",
   "metadata": {},
   "source": [
    "<hr style= \"border:2px solid black\"> </hr>\n",
    "\n",
    "## Table of Contents\n",
    "[1. Data Extraction](#Overview)\n",
    "  - [1.1 Setup and helpers](#Setup_and_helpers)\n",
    "  - [1.2 Download Section](#Download_Section)\n",
    "    \n",
    "[2. Overview of the data](#Overview_of_the_data)\n",
    "  - [2.1 Statistical Report](#Statistics)\n",
    "  - [2.2 Visualizations](#Visualizations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab464de7-3c32-48b4-8bee-e9b689084011",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b574bde",
   "metadata": {},
   "source": [
    "Goal: Download ERA5 single and pressure levels (hourly, monthly) and IMERG Half-Hourly (30 min) for 2015.\n",
    "- IMERG path: raw/imerg/YYYY/MM/imerg_<original>.HDF5\n",
    "- ERA5: per variable per month\n",
    "- IMERG: per month\n",
    "- Region: dict(north=62.0, south=49.0, west=-13.0, east=3.5)\n",
    "- Root path: D:\\\\extreme_rainfalls\\\\\n",
    "- Set up Copernicus API: create ~/.cdsapirc with your key.\n",
    "- Set up NASA Earthdata: create ~/.netrc with credentials for urs.earthdata.nasa.gov."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49bb85f-a4bb-42e8-886c-04648ac685bd",
   "metadata": {},
   "source": [
    "### 1.1 Setup and helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99398a-20a2-44b2-a975-889ebb4c2aaf",
   "metadata": {},
   "source": [
    "#### Environment Setup\n",
    "- To Setup all packages in anaconda, conda install environment.yml in anaconda prompt\n",
    "- To Setup all packages in windows, pip install erequirements.txt in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c16fa6b4-2c9d-4e52-a689-3ee23395bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, subprocess, shutil, site, re, time, glob\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "from __future__ import annotations\n",
    "import json, sys, math, errno\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92fd515-c9ab-488e-8c6a-357be109d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 single: OK | pl: OK | imerg: OK\n",
      "2016 single: OK | pl: OK | imerg: OK\n",
      "2017 single: OK | pl: OK | imerg: OK\n",
      "2018 single: OK | pl: OK | imerg: OK\n",
      "2019 single: OK | pl: OK | imerg: OK\n",
      "2020 single: OK | pl: OK | imerg: OK\n",
      "2021 single: OK | pl: OK | imerg: OK\n",
      "2022 single: OK | pl: OK | imerg: OK\n",
      "2023 single: OK | pl: OK | imerg: OK\n",
      "2024 single: OK | pl: OK | imerg: OK\n",
      "Raw data dir: D:\\extreme_rainfalls\\data\\raw\n",
      "Status file: D:\\extreme_rainfalls\\data\\_status\\download_status.json\n"
     ]
    }
   ],
   "source": [
    "# Imports and config\n",
    "import os, time, json, calendar, requests\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    import cdsapi\n",
    "except Exception:\n",
    "    print(\"Install cdsapi if you plan to download ERA5: pip install cdsapi\")\n",
    "\n",
    "# >>> FIX: make BASE_DIR a Path, not a str (and keep it portable)\n",
    "# Use your Windows path if it exists, otherwise fall back to a home-based folder.\n",
    "win_base = Path(r\"D:\\extreme_rainfalls\")\n",
    "BASE_DIR = win_base if win_base.exists() else (Path.home() / \"extreme_rainfalls\")\n",
    "BASE_DIR = BASE_DIR.resolve()\n",
    "\n",
    "RAW_DIR = (BASE_DIR / \"data\" / \"raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)  # optional: ensure it exists\n",
    "\n",
    "YEARS = list(range(2015, 2025))\n",
    "\n",
    "# UK window\n",
    "REGION = dict(north=62.0, south=49.0, west=-13.0, east=3.5)\n",
    "\n",
    "ERA5_SINGLE_VARS = [\n",
    "    \"total_precipitation\", \"convective_precipitation\", \"2m_temperature\",\n",
    "    \"10m_u_component_of_wind\", \"10m_v_component_of_wind\",\n",
    "    \"surface_pressure\", \"total_column_water_vapour\",\n",
    "    \"total_column_cloud_liquid_water\", \"boundary_layer_height\", \"mean_sea_level_pressure\"\n",
    "]\n",
    "ERA5_PL_LEVELS = [\"850\",\"700\",\"500\",\"300\"]\n",
    "ERA5_PL_VARS = [\"specific_humidity\",\"u_component_of_wind\",\"v_component_of_wind\",\n",
    "                \"geopotential\",\"relative_humidity\",\"temperature\"]\n",
    "\n",
    "IMERG_VARS = [\n",
    "    \"precipitationCal\",\n",
    "    \"precipitationUncal\",\n",
    "    \"precipitationQualityIndex\",\n",
    "    \"randomError\",\n",
    "    \"probabilityLiquidPrecipitation\"\n",
    "]\n",
    "\n",
    "# Subregions for credible evaluation and weighting\n",
    "SUBREGIONS = {\n",
    "    \"West_Highlands\": dict(north=58.0, south=56.0, west=-6.5, east=-4.0),\n",
    "    \"Lake_District\":  dict(north=55.0, south=54.2, west=-3.5, east=-2.7),\n",
    "    \"Snowdonia\":      dict(north=53.3, south=52.7, west=-4.2, east=-3.3),\n",
    "}\n",
    "\n",
    "imerg_months = list(range(1, 13))  \n",
    "\n",
    "def dir_era5_single(y):  return RAW_DIR / \"era5_single\"   / str(y)\n",
    "def dir_era5_pl(y):      return RAW_DIR / \"era5_pressure\" / str(y)\n",
    "def dir_imerg(y):        return RAW_DIR / \"imerg\"         / str(y)\n",
    "\n",
    "\n",
    "for y in YEARS:\n",
    "    print(\n",
    "        y,\n",
    "        \"single:\", \"OK\" if dir_era5_single(y).exists() else \"MISSING\",\n",
    "        \"| pl:\",   \"OK\" if dir_era5_pl(y).exists()     else \"MISSING\",\n",
    "        \"| imerg:\",\"OK\" if dir_imerg(y).exists()        else \"MISSING\"\n",
    "    )\n",
    "\n",
    "STATUS_DIR = Path(BASE_DIR) / \"data\" / \"_status\"\n",
    "STATUS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STATUS_FILE = STATUS_DIR / \"download_status.json\"\n",
    "print(\"Raw data dir:\", RAW_DIR)\n",
    "print(\"Status file:\", STATUS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff030c-1159-42a0-a3ce-d50824908074",
   "metadata": {},
   "source": [
    "- The above results explains data from 2015 to 2015 is downloaded in the raw directory and is verified as available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5720d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status helpers\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def load_status(path: Path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            return json.loads(path.read_text())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def save_status(path: Path, status: dict):\n",
    "    path.write_text(json.dumps(status, indent=2))\n",
    "\n",
    "def mark_status(status: dict, group: str, key: str, value: str):\n",
    "    \"\"\"\n",
    "    Mark a (group, key) entry with a state and UTC timestamp.\n",
    "    States: 'queued' | 'downloading' | 'done' | 'skipped' | 'error'\n",
    "    Example keys:\n",
    "      group='era5_single', key='total_precipitation_201501'\n",
    "      group='era5_pl',     key='specific_humidity_L850_201501'\n",
    "      group='imerg_month', key='201501'\n",
    "      group='imerg_file',  key='<original HDF5 name>'\n",
    "    \"\"\"\n",
    "    status.setdefault(group, {})\n",
    "    status[group][key] = {\"state\": value, \"timestamp\": datetime.utcnow().isoformat() + \"Z\"}\n",
    "    return status\n",
    "\n",
    "def pretty_print_status(status: dict):\n",
    "    import pandas as pd\n",
    "    rows = []\n",
    "    for group, items in status.items():\n",
    "        for k, v in items.items():\n",
    "            rows.append({\"Group\": group, \"Item\": k, \"State\": v.get(\"state\"), \"Updated\": v.get(\"timestamp\")})\n",
    "    if rows:\n",
    "        df = pd.DataFrame(rows).sort_values([\"Group\",\"Item\"])\n",
    "        try:\n",
    "            from caas_jupyter_tools import display_dataframe_to_user\n",
    "            display_dataframe_to_user(\"Download Status\", df)\n",
    "        except Exception:\n",
    "            print(df)\n",
    "    else:\n",
    "        print(\"No status yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a558304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _area_from_region(region: dict):\n",
    "    return [region[\"north\"], region[\"west\"], region[\"south\"], region[\"east\"]]\n",
    "\n",
    "def download_era5_single_by_variable(year, variables, region, out_dir, status_path):\n",
    "    \"\"\"\n",
    "    Download ERA5 single-level variables for multiple years and months.\n",
    "    \n",
    "    Args:\n",
    "        years       (iterable): List or range of years (e.g., range(2016, 2022)).\n",
    "        variables   (list)    : ERA5 single-level variables.\n",
    "        region      (dict)    : Bounding box {north, south, west, east}.\n",
    "        out_dir     (Path)    : Output directory root.\n",
    "        status_path (Path)    : Path to status JSON file.\n",
    "    \"\"\"\n",
    "    status = load_status(status_path)\n",
    "    area   = _area_from_region(region)\n",
    "    times  = [f\"{h:02d}:00\" for h in range(24)]\n",
    "    c      = cdsapi.Client()\n",
    "\n",
    "    for var in tqdm(variables, desc=\"ERA5 single vars\"):        \n",
    "            for month in range(1, 13):\n",
    "                mstr = f\"{month:02d}\"\n",
    "                key  = f\"{var}_{year}_{mstr}\"\n",
    "                year_dir = out_dir / str(year)\n",
    "                year_dir.mkdir(parents=True, exist_ok=True)\n",
    "                target = year_dir / f\"era5_single_{var}_{year}{mstr}.nc\"\n",
    "            \n",
    "\n",
    "                if target.exists():\n",
    "                    status = mark_status(status, 'era5_single', key, 'skipped')\n",
    "                    save_status(status_path, status)\n",
    "                    continue\n",
    "\n",
    "                status = mark_status(status, 'era5_single', key, 'downloading')\n",
    "                save_status(status_path, status)\n",
    "\n",
    "                days = [f\"{d:02d}\" for d in range(1, calendar.monthrange(year, month)[1] + 1)]\n",
    "                try:\n",
    "                    r = c.retrieve(\n",
    "                        \"reanalysis-era5-single-levels\",\n",
    "                        {\n",
    "                            \"product_type\": \"reanalysis\",\n",
    "                            \"variable\": [var],\n",
    "                            \"year\": str(year),\n",
    "                            \"month\": mstr,\n",
    "                            \"day\": days,\n",
    "                            \"time\": times,\n",
    "                            \"area\": area,\n",
    "                            \"format\": \"netcdf\",\n",
    "                        }\n",
    "                    )\n",
    "                    r.download(str(target))\n",
    "                    status = mark_status(status, 'era5_single', key, 'done')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error for {key}:\", e)\n",
    "                    status = mark_status(status, 'era5_single', key, 'error')\n",
    "\n",
    "                save_status(status_path, status)\n",
    "\n",
    "    return load_status(status_path)\n",
    "\n",
    "\n",
    "def download_era5_pl_by_var_level(year, variables, levels, region, out_dir, status_path):\n",
    "    \"\"\"\n",
    "    Download ERA5 pressure-level variables for multiple years, months, and levels.\n",
    "\n",
    "    Args:\n",
    "        years       (iterable): List or range of years (e.g., range(2016, 2022)).\n",
    "        variables   (list)    : ERA5 pressure-level variables.\n",
    "        levels      (list)    : Pressure levels in hPa (e.g., [\"925\", \"850\", \"700\"]).\n",
    "        region      (dict)    : Bounding box {north, south, west, east}.\n",
    "        out_dir     (Path)    : Output directory root.\n",
    "        status_path (Path)    : Path to status JSON file.\n",
    "    \"\"\"\n",
    "    status = load_status(status_path)\n",
    "    area   = _area_from_region(region)\n",
    "    times  = [f\"{h:02d}:00\" for h in range(24)]\n",
    "    c      = cdsapi.Client()\n",
    "\n",
    "    for var in tqdm(variables, desc=\"ERA5 PL vars\"):\n",
    "        for lev in tqdm(levels, leave=False, desc=f\"{var} levels\"):           \n",
    "                for month in range(1, 13):\n",
    "                    mstr = f\"{month:02d}\"\n",
    "                    key  = f\"{var}_L{lev}_{year}_{mstr}\"\n",
    "                    year_dir = out_dir / str(year)\n",
    "                    year_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    target = year_dir / f\"era5_pl_{var}_L{lev}_{year}{mstr}.nc\"\n",
    "\n",
    "                    if target.exists():\n",
    "                        status = mark_status(status, 'era5_pl', key, 'skipped')\n",
    "                        save_status(status_path, status)\n",
    "                        continue\n",
    "\n",
    "                    status = mark_status(status, 'era5_pl', key, 'downloading')\n",
    "                    save_status(status_path, status)\n",
    "\n",
    "                    days = [f\"{d:02d}\" for d in range(1, calendar.monthrange(year, month)[1] + 1)]\n",
    "                    try:\n",
    "                        r = c.retrieve(\n",
    "                            \"reanalysis-era5-pressure-levels\",\n",
    "                            {\n",
    "                                \"product_type\": \"reanalysis\",\n",
    "                                \"variable\": [var],\n",
    "                                \"pressure_level\": [lev],\n",
    "                                \"year\": str(year),\n",
    "                                \"month\": mstr,\n",
    "                                \"day\": days,\n",
    "                                \"time\": times,\n",
    "                                \"area\": area,\n",
    "                                \"format\": \"netcdf\",\n",
    "                            }\n",
    "                        )\n",
    "                        r.download(str(target))\n",
    "                        status = mark_status(status, 'era5_pl', key, 'done')\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error for {key}:\", e)\n",
    "                        status = mark_status(status, 'era5_pl', key, 'error')\n",
    "\n",
    "                    save_status(status_path, status)\n",
    "\n",
    "    return load_status(status_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4929a505-fcf2-431a-8938-e74765fef02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- IMERG via GES DISC Subset Service --------------------\n",
    "def _earthdata_session():\n",
    "    \"\"\"\n",
    "    Return a requests.Session that authenticates via ~/.netrc for GES DISC.\n",
    "    \"\"\"\n",
    "    import netrc, requests\n",
    "    s = requests.Session()\n",
    "    try:\n",
    "        _ = netrc.netrc()\n",
    "    except FileNotFoundError:\n",
    "        print(\"~/.netrc missing. Add Earthdata creds.\")\n",
    "    s.trust_env = True\n",
    "    try:\n",
    "        s.get(\"https://gpm1.gesdisc.eosdis.nasa.gov/data/\", timeout=30)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return s\n",
    "\n",
    "def list_imerg_files(year, month):\n",
    "    \"\"\"\n",
    "    Query NASA CMR API to get all valid IMERG V07 half-hourly granules for a given month.\n",
    "    Returns a list of full download URLs (with orbit numbers).\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from datetime import datetime\n",
    "    from calendar import monthrange\n",
    "\n",
    "    start = datetime(year, month, 1)\n",
    "    end = datetime(year, month, monthrange(year, month)[1])\n",
    "\n",
    "    temporal = f\"{start:%Y-%m-%dT00:00:00Z},{end:%Y-%m-%dT23:59:59Z}\"\n",
    "    url = (\n",
    "        \"https://cmr.earthdata.nasa.gov/search/granules.json\"\n",
    "        \"?short_name=GPM_3IMERGHH\"\n",
    "        \"&version=07\"\n",
    "        f\"&temporal={temporal}\"\n",
    "        \"&page_size=2000\"\n",
    "    )\n",
    "\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "\n",
    "    files = []\n",
    "    for entry in data.get(\"feed\", {}).get(\"entry\", []):\n",
    "        for link in entry.get(\"links\", []):\n",
    "            if \"href\" in link and link[\"href\"].endswith(\".HDF5\"):\n",
    "                files.append(link[\"href\"])\n",
    "    return files\n",
    "\n",
    "\n",
    "\n",
    "def validate_imerg_file(nc_path, expected_vars=IMERG_VARS):\n",
    "    \"\"\"\n",
    "    Check if all expected IMERG variables exist and contain data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import xarray as xr\n",
    "        ds = xr.open_dataset(nc_path, engine=\"netcdf4\")  # ✅ force backend\n",
    "        missing = [v for v in expected_vars if v not in ds.variables]\n",
    "        if missing:\n",
    "            print(f\"[WARN] {nc_path.name}: missing {missing}\")\n",
    "            return False\n",
    "        for v in expected_vars:\n",
    "            if ds[v].size == 0:\n",
    "                print(f\"[WARN] {nc_path.name}: variable {v} has no data\")\n",
    "                return False\n",
    "        print(f\"[OK] {nc_path.name}: all variables present with data\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {nc_path.name}: {e}\")\n",
    "        return False\n",
    "\n",
    "        \n",
    "def imerg_hhr_file_urls_for_day(date):\n",
    "    \"\"\"\n",
    "    Build all 30-min IMERG V07 granule URLs for a given day.\n",
    "    \"\"\"\n",
    "\n",
    "    base = \"https://gpm1.gesdisc.eosdis.nasa.gov/data/GPM_L3/IMERG/HH\"\n",
    "    yyyy = date.strftime(\"%Y\")\n",
    "    mm = date.strftime(\"%m\")\n",
    "    yyyymmdd = date.strftime(\"%Y%m%d\")\n",
    "    urls = []\n",
    "    for hh in range(24):\n",
    "        for mm_ in (0, 30):\n",
    "            start = f\"S{hh:02d}{mm_:02d}00\"\n",
    "            end_dt = (datetime(date.year, date.month, date.day, hh, mm_)\n",
    "                      + timedelta(minutes=30) - timedelta(seconds=1))\n",
    "            end = f\"E{end_dt.strftime('%H%M%S')}\"\n",
    "            urls.append(\n",
    "                f\"{base}/{yyyy}/{mm}/3B-HHR.MS.MRG.3IMERG.{yyyymmdd}-{start}-{end}.0000.V07B.HDF5\"\n",
    "            )\n",
    "    return urls\n",
    "\n",
    "\n",
    "def _subset_params_for_day(date, variables, region, label, bbox_order=\"swne\"):\n",
    "    \"\"\"\n",
    "    Construct parameters for GES DISC OTF Subset Service.\n",
    "    \"\"\"\n",
    "    filenames = [u.replace(\"https://gpm1.gesdisc.eosdis.nasa.gov\", \"\")\n",
    "                 for u in imerg_hhr_file_urls_for_day(date)]\n",
    "    params = []\n",
    "    for f in filenames:\n",
    "        if not f.startswith(\"/data\"):\n",
    "            f = \"/data\" + f\n",
    "        params.append((\"FILENAME\", f))\n",
    "\n",
    "    if bbox_order == \"swne\":\n",
    "        bbox = f\"{region['south']},{region['west']},{region['north']},{region['east']}\"\n",
    "    else:\n",
    "        bbox = f\"{region['north']},{region['west']},{region['south']},{region['east']}\"\n",
    "\n",
    "    params.extend([\n",
    "        (\"FORMAT\", \"NetCDF4\"),\n",
    "        (\"BBOX\", bbox),\n",
    "        (\"VARIABLES\", \",\".join(variables)),\n",
    "        (\"LABEL\", f\"{label}.nc\"),\n",
    "    ])\n",
    "    return params\n",
    "\n",
    "\n",
    "def _stream_subset_request(session, params, out_nc, timeout=1800):\n",
    "    \"\"\"\n",
    "    Make the subset request and save output NetCDF to disk.\n",
    "    Returns (ok: bool, msg: str).\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    url = \"https://gpm1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi\"\n",
    "    headers = {\"User-Agent\": \"subset-client/0.1\"}\n",
    "    with session.get(url, params=params, stream=True, timeout=timeout, headers=headers) as r:\n",
    "        if r.status_code != 200:\n",
    "            return False, f\"HTTP {r.status_code}\"\n",
    "        with open(out_nc, \"wb\") as f:\n",
    "            for chunk in r.iter_content(1024 * 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return True, \"ok\"\n",
    "\n",
    "def download_imerg_raw_day(date, out_dir, status_path):\n",
    "    \"\"\"\n",
    "    Download all IMERG V07 half-hourly HDF5 granules for a given day.\n",
    "    Saves them as:\n",
    "      raw/imerg/YYYY/MM/imerg_YYYYMMDD_HHMM.HDF5\n",
    "    \"\"\"\n",
    "    status = load_status(status_path)\n",
    "    day_key = date.strftime(\"%Y%m%d\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    urls = imerg_hhr_file_urls_for_day(date)\n",
    "    s = _earthdata_session()\n",
    "\n",
    "    for url in urls:\n",
    "        fname = url.split(\"/\")[-1]\n",
    "        out_file = out_dir / fname\n",
    "\n",
    "        if out_file.exists():\n",
    "            status = mark_status(status, 'imerg_raw', fname, 'skipped')\n",
    "            continue\n",
    "\n",
    "        r = s.get(url, stream=True, timeout=600)\n",
    "        if r.status_code == 200:\n",
    "            with open(out_file, \"wb\") as f:\n",
    "                for chunk in r.iter_content(1024*1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            status = mark_status(status, 'imerg_raw', fname, 'done')\n",
    "        else:\n",
    "            print(f\"[ERROR] {url} → HTTP {r.status_code}\")\n",
    "            status = mark_status(status, 'imerg_raw', fname, 'error')\n",
    "\n",
    "    save_status(status_path, status)\n",
    "\n",
    "\n",
    "def download_imerg_raw_month(year, month, out_dir, status_path):\n",
    "    \"\"\"\n",
    "    Download all IMERG V07 half-hourly HDF5 granules for a given month\n",
    "    using CMR-discovered URLs.\n",
    "    \"\"\"\n",
    "    status = load_status(status_path)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = list_imerg_files(year, month)\n",
    "    if not files:\n",
    "        print(f\"[WARN] No files found for {year}-{month:02d}\")\n",
    "        return\n",
    "\n",
    "    s = _earthdata_session()\n",
    "\n",
    "    for url in files:\n",
    "        fname = url.split(\"/\")[-1]\n",
    "        out_file = out_dir / fname\n",
    "\n",
    "        if out_file.exists():\n",
    "            status = mark_status(status, 'imerg_raw', fname, 'skipped')\n",
    "            continue\n",
    "\n",
    "        r = s.get(url, stream=True, timeout=600)\n",
    "        if r.status_code == 200:\n",
    "            with open(out_file, \"wb\") as f:\n",
    "                for chunk in r.iter_content(1024*1024):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            status = mark_status(status, 'imerg_raw', fname, 'done')\n",
    "            print(f\"[OK] {fname}\")\n",
    "        else:\n",
    "            print(f\"[ERROR] {url} → HTTP {r.status_code}\")\n",
    "            status = mark_status(status, 'imerg_raw', fname, 'error')\n",
    "\n",
    "    save_status(status_path, status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d5a17-a5c0-4a2c-838e-16fbd6f6b504",
   "metadata": {},
   "source": [
    "### 1.2 Download Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb29321-2fef-4986-8e6e-f78905149978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads skipped — data already available locally.\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Download Section (DISABLED because data is already downloaded)\n",
    "# ===========================================================\n",
    "\n",
    "RUN_DOWNLOADS = False   #  change to True ONLY, for re-download\n",
    "\n",
    "if RUN_DOWNLOADS:\n",
    "    # ----------------- ERA5 single-level -----------------\n",
    "    print(\"\\n=== ERA5 single-level downloads ===\")\n",
    "    for y in YEARS:\n",
    "        out_dir_single = dir_era5_single(y)  # e.g., RAW_DIR/era5_single/YYYY\n",
    "        out_dir_single.mkdir(parents=True, exist_ok=True)\n",
    "        download_era5_single_by_variable(\n",
    "            year=y,\n",
    "            variables=ERA5_SINGLE_VARS,\n",
    "            region=REGION,\n",
    "            out_dir=out_dir_single,\n",
    "            status_path=STATUS_FILE,\n",
    "        )   \n",
    "    pretty_print_status(load_status(STATUS_FILE))    \n",
    "\n",
    "    # ----------------- ERA5 pressure-level -----------------\n",
    "    print(\"\\n=== ERA5 pressure-level downloads ===\")\n",
    "    for y in YEARS:\n",
    "        out_dir_pl = dir_era5_pl(y)  # e.g., RAW_DIR/era5_pressure/YYYY\n",
    "        out_dir_pl.mkdir(parents=True, exist_ok=True)\n",
    "        download_era5_pl_by_var_level(\n",
    "            year=y,\n",
    "            variables=ERA5_PL_VARS,\n",
    "            levels=ERA5_PL_LEVELS,\n",
    "            region=REGION,\n",
    "            out_dir=out_dir_pl,\n",
    "            status_path=STATUS_FILE,\n",
    "        )    \n",
    "    pretty_print_status(load_status(STATUS_FILE))\n",
    "\n",
    "    # ----------------- IMERG (raw HDF5 via catalog) -----------------\n",
    "    print(\"\\n=== IMERG (Raw HDF5 via Catalog) downloads ===\")\n",
    "    for y in YEARS:\n",
    "        for month in imerg_months:\n",
    "            out_dir = dir_imerg(y) / f\"{month:02d}\"   # RAW_DIR/imerg/YYYY/MM\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            download_imerg_raw_month(\n",
    "                year=y,\n",
    "                month=month,\n",
    "                out_dir=out_dir,\n",
    "                status_path=STATUS_FILE,\n",
    "            )\n",
    "    pretty_print_status(load_status(STATUS_FILE))\n",
    "\n",
    "else:\n",
    "    print(\"Downloads skipped — data already available locally.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04abddb6-8b86-4a5d-bd62-587b5a755846",
   "metadata": {},
   "source": [
    "# 2. Overview of the data\n",
    "- We inspect ERA5 single-level, ERA5 pressure-level, and IMERG rainfall datasets.  \n",
    "- This helps confirm temporal coverage, spatial extent, and variable availability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e78249-0297-406a-8b90-cab8342d95aa",
   "metadata": {},
   "source": [
    "### Statistical Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6f058-df68-4a28-88a9-0e9494bec57c",
   "metadata": {},
   "source": [
    "#### Load File Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1536384-ff0a-4a52-95cc-e368cba34dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5 single files: 1280\n",
      "ERA5 pressure files: 3072\n",
      "IMERG files: 181104\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "# Define raw data directories (following your style)\n",
    "ERA5_SINGLE_RAW = RAW_DIR / \"era5_single\"\n",
    "ERA5_PL_RAW     = RAW_DIR / \"era5_pressure\"\n",
    "IMERG_RAW       = RAW_DIR / \"imerg\"\n",
    "\n",
    "# Recursively search all subfolders (year/month)\n",
    "era5_single_files = sorted(ERA5_SINGLE_RAW.rglob(\"*.nc\"))\n",
    "era5_pl_files     = sorted(ERA5_PL_RAW.rglob(\"*.nc\"))\n",
    "imerg_files       = sorted(list(IMERG_RAW.rglob(\"*.HDF5\")) + list(IMERG_RAW.rglob(\"*.nc4\")))\n",
    "\n",
    "print(\"ERA5 single files:\", len(era5_single_files))\n",
    "print(\"ERA5 pressure files:\", len(era5_pl_files))\n",
    "print(\"IMERG files:\", len(imerg_files))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f4900-e1c6-46db-aa1a-aa0df35095a5",
   "metadata": {},
   "source": [
    "#### Display sample files\n",
    "- We load one file from each source using `xarray.open_dataset()`.\n",
    "- To check variables, dimensions, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04edc054-b0df-4baf-82cb-eac7d2c9839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5 single sample:\n",
      " <xarray.Dataset> Size: 11MB\n",
      "Dimensions:     (valid_time: 744, latitude: 53, longitude: 67)\n",
      "Coordinates:\n",
      "    number      int64 8B ...\n",
      "  * valid_time  (valid_time) datetime64[ns] 6kB 2015-01-01 ... 2015-01-31T23:...\n",
      "  * latitude    (latitude) float64 424B 62.0 61.75 61.5 ... 49.5 49.25 49.0\n",
      "  * longitude   (longitude) float64 536B -13.0 -12.75 -12.5 ... 3.0 3.25 3.5\n",
      "    expver      (valid_time) <U4 12kB ...\n",
      "Data variables:\n",
      "    u10         (valid_time, latitude, longitude) float32 11MB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-08-26T23:33 GRIB to CDM+CF via cfgrib-0.9.1...\n",
      "ERA5 pressure sample:\n",
      " <xarray.Dataset> Size: 11MB\n",
      "Dimensions:         (valid_time: 744, pressure_level: 1, latitude: 53,\n",
      "                     longitude: 67)\n",
      "Coordinates:\n",
      "    number          int64 8B ...\n",
      "  * valid_time      (valid_time) datetime64[ns] 6kB 2015-01-01 ... 2015-01-31...\n",
      "  * pressure_level  (pressure_level) float64 8B 300.0\n",
      "  * latitude        (latitude) float64 424B 62.0 61.75 61.5 ... 49.5 49.25 49.0\n",
      "  * longitude       (longitude) float64 536B -13.0 -12.75 -12.5 ... 3.0 3.25 3.5\n",
      "    expver          (valid_time) <U4 12kB ...\n",
      "Data variables:\n",
      "    z               (valid_time, pressure_level, latitude, longitude) float32 11MB ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2025-08-28T03:06 GRIB to CDM+CF via cfgrib-0.9.1...\n",
      "IMERG sample:\n",
      " <xarray.Dataset> Size: 0B\n",
      "Dimensions:  ()\n",
      "Data variables:\n",
      "    *empty*\n",
      "Attributes:\n",
      "    FileHeader:  DOI=10.5067/GPM/IMERG/3B-HH/07;\\nDOIauthority=http://dx.doi....\n",
      "    FileInfo:    DataFormatVersion=7e;\\nTKCodeBuildVersion=0;\\nMetadataVersio...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Load sample files (only if available) ---\n",
    "if era5_single_files:\n",
    "    ds_single = xr.open_dataset(era5_single_files[0])\n",
    "    print(\"ERA5 single sample:\\n\", ds_single)\n",
    "\n",
    "if era5_pl_files:\n",
    "    ds_pl = xr.open_dataset(era5_pl_files[0])\n",
    "    print(\"ERA5 pressure sample:\\n\", ds_pl)\n",
    "\n",
    "if imerg_files:\n",
    "    ds_imerg = xr.open_dataset(imerg_files[0])\n",
    "    print(\"IMERG sample:\\n\", ds_imerg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca212ec1-1db9-4d33-9f29-e9595640092f",
   "metadata": {},
   "source": [
    "#### Variables and Dimensions\n",
    "- `ds.data_vars` shows available variables.  \n",
    "- `ds.dims` tells us spatial and temporal resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e001d211-faeb-42b4-a334-d57e783fe3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5 single variables: ['u10']\n",
      "ERA5 pressure variables: ['z']\n",
      "IMERG variables: []\n",
      "\n",
      "ERA5 single dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 744, 'latitude': 53, 'longitude': 67})\n",
      "ERA5 pressure dimensions: FrozenMappingWarningOnValuesAccess({'valid_time': 744, 'pressure_level': 1, 'latitude': 53, 'longitude': 67})\n",
      "IMERG dimensions: FrozenMappingWarningOnValuesAccess({})\n"
     ]
    }
   ],
   "source": [
    "print(\"ERA5 single variables:\", list(ds_single.data_vars))\n",
    "print(\"ERA5 pressure variables:\", list(ds_pl.data_vars))\n",
    "print(\"IMERG variables:\", list(ds_imerg.data_vars))\n",
    "\n",
    "print(\"\\nERA5 single dimensions:\", ds_single.dims)\n",
    "print(\"ERA5 pressure dimensions:\", ds_pl.dims)\n",
    "print(\"IMERG dimensions:\", ds_imerg.dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cfefa0-c40c-41ec-98a0-653e17718d81",
   "metadata": {},
   "source": [
    "#### Spatial Coverage\n",
    "- We confirm latitude/longitude ranges cover the UK domain.  \n",
    "- This avoids errors if files contain global data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68185a83-11c5-4cf0-a388-39e4cdb3be1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5 single lat/lon: 49.0 → 62.0 -13.0 → 3.5\n",
      "ERA5 pressure lat/lon: 49.0 → 62.0 -13.0 → 3.5\n"
     ]
    }
   ],
   "source": [
    "print(\"ERA5 single lat/lon:\", float(ds_single.latitude.min()), \"→\", float(ds_single.latitude.max()),\n",
    "      float(ds_single.longitude.min()), \"→\", float(ds_single.longitude.max()))\n",
    "\n",
    "print(\"ERA5 pressure lat/lon:\", float(ds_pl.latitude.min()), \"→\", float(ds_pl.latitude.max()),\n",
    "      float(ds_pl.longitude.min()), \"→\", float(ds_pl.longitude.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e5ca9-190c-48e0-98ad-6488bb4c651e",
   "metadata": {},
   "source": [
    "### Summary\n",
    "- File counts confirm dataset availability.  \n",
    "- Variables & dimensions confirm correct structure.  \n",
    "-  lat/lon confirm alignment with project domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309334d0-02dd-4c19-bd92-37a83e371bdf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dee2dd-b179-4b7d-9084-1a7fec8fe7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a47f6-6712-452f-be57-f84c19cf78a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rain311)",
   "language": "python",
   "name": "rain311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
